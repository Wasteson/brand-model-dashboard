total_artikler <- n_distinct(x$ArtikkelId)
# Finn kunder som har klikket pÃ¥ alle artiklene
klikket_alle <- x %>%
filter(!is.na(Dato_klikket)) %>%   # Kun rader med klikk
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId)
) %>%
filter(antall_klikkede_artikler == total_artikler)  # KundeNr som klikket pÃ¥ alle artikler
# Skriv ut resultatet
print(klikket_alle)
# Filtrer rader der klikk er mer enn 1 minutt fÃ¸r Ã¥pning
x_autoklikk_apnetminut <- x_klikk %>%
filter(
Dato_klikket < Ã…pnet,
as.numeric(difftime(Ã…pnet, Dato_klikket, units = "secs")) > 60
)
# Filtrer rader der klikk er mer enn 1 minutt fÃ¸r sending
x_autoklikk_sendtminut <- x_klikk %>%
filter(
Dato_klikket < Sendt,
as.numeric(difftime(Sendt, Dato_klikket, units = "secs")) > 60
)
dim(x_autoklikk_sendtminut)
dim(x_autoklikk_apnetminut)
head(x, 3)
head(x, 20)
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk twe utsid 124098.csv", fileEncoding = "UTF-16LE", sep = "\t")
head(x, 20)
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD_uttrekk_twe_utsid_124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S")
)
file.exists("~/Desktop/360 programmer/JN25-008/OD_uttrekk_twe_utsid_124098.csv")
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk twe utsid 124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S")
)
# Hent totalt antall artikler i brevet
total_artikler <- x %>%
filter(!is.na(ArtikkelId)) %>%
n_distinct(ArtikkelId)
names(x)
print(names(x))
dput(names(x))
sum(!is.na(x$ArtikkelId))  # Hvor mange ikke-NA verdier?
unique(x$ArtikkelId)        # Se hvilke verdier som finnes
str(x$ArtikkelId)
library(janitor)  # For clean_names() hvis nÃ¸dvendig
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD_uttrekk_twe_utsid_124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
install.packages("janitor")
library(janitor)  # For clean_names() hvis nÃ¸dvendig
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD_uttrekk_twe_utsid_124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk twe utsid 124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
# Hent totalt antall artikler i brevet (fikset med `as.character()`)
total_artikler <- x %>%
filter(!is.na(ArtikkelId)) %>%
summarise(n_distinct(ArtikkelId)) %>%
pull()
cat("Totalt antall unike artikler i brevet:", total_artikler, "\n")
# Filtrer kun rader med registrerte klikk
x_klikk <- x %>% filter(!is.na(Dato_klikket))
### ðŸ“Œ 2. Finn serverclicks basert pÃ¥ klikk FÃ˜R Ã¥pning
serverclick_foer_apning <- x_klikk %>%
filter(Dato_klikket < Ã…pnet) %>%
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle | antall_klikkede_artikler >= 2)  # Klikk pÃ¥ alle eller minst 2 artikler
### ðŸ“Œ 3. Finn serverclicks basert pÃ¥ klikk KORT tid etter Ã¥pning (f.eks. 10 sek)
serverclick_etter_apning <- x_klikk %>%
filter(!is.na(Ã…pnet)) %>%
mutate(tidsdiff = as.numeric(difftime(Dato_klikket, Ã…pnet, units = "secs"))) %>%
filter(tidsdiff <= 10) %>%  # Juster terskel (kan teste 10, 20, 30 sekunder)
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle | antall_klikkede_artikler >= 2)  # Klikk pÃ¥ alle eller minst 2 artikler
### ðŸ“Œ 4. Kombiner og tell antall serverclicks
serverclicks <- bind_rows(serverclick_foer_apning, serverclick_etter_apning) %>%
distinct(KundeNr)  # Fjern duplikater (samme kunde kan dukke opp i begge filtrene)
antall_serverclicks <- nrow(serverclicks)
totale_klikk <- nrow(x_klikk)
totale_unike_klikkere <- n_distinct(x_klikk$KundeNr)
# Beregn serverclick-rate
serverclick_pct_klikk <- (antall_serverclicks / totale_klikk) * 100
serverclick_pct_unike <- (antall_serverclicks / totale_unike_klikkere) * 100
### ðŸ“Œ 5. Skriv ut resultater
cat("\nðŸ” **Serverclick-analyse** ðŸ”\n")
cat("1ï¸âƒ£ Totalt antall klikk:", totale_klikk, "\n")
cat("2ï¸âƒ£ Totalt antall unike klikkere:", totale_unike_klikkere, "\n")
cat("3ï¸âƒ£ Totalt antall serverclicks (mistanke):", antall_serverclicks, "\n")
cat("4ï¸âƒ£ Serverclicks som andel av alle klikk:", round(serverclick_pct_klikk, 2), "%\n")
cat("5ï¸âƒ£ Serverclicks som andel av unike klikkere:", round(serverclick_pct_unike, 2), "%\n")
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk twe utsid 124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
# Hent totalt antall artikler i brevet (fikset med `as.character()`)
total_artikler <- x %>%
filter(!is.na(ArtikkelId)) %>%
summarise(n_distinct(ArtikkelId)) %>%
pull()
cat("Totalt antall unike artikler i brevet:", total_artikler, "\n")
# Filtrer kun rader med registrerte klikk
x_klikk <- x %>% filter(!is.na(Dato_klikket))
### ðŸ“Œ 2. Finn serverclicks basert pÃ¥ klikk FÃ˜R Ã¥pning
serverclick_foer_apning <- x_klikk %>%
filter(Dato_klikket < Ã…pnet) %>%
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle | antall_klikkede_artikler >= 2)  # Klikk pÃ¥ alle eller minst 2 artikler
### ðŸ“Œ 3. Finn serverclicks basert pÃ¥ klikk KORT tid etter Ã¥pning (f.eks. 10 sek)
serverclick_etter_apning <- x_klikk %>%
filter(!is.na(Ã…pnet)) %>%
mutate(tidsdiff = as.numeric(difftime(Dato_klikket, Ã…pnet, units = "secs"))) %>%
filter(tidsdiff <= 0) %>%  # Juster terskel (kan teste 10, 20, 30 sekunder)
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle)  # Klikk pÃ¥ alle artikler
### ðŸ“Œ 4. Kombiner og tell antall serverclicks
serverclicks <- bind_rows(serverclick_foer_apning, serverclick_etter_apning) %>%
distinct(KundeNr)  # Fjern duplikater (samme kunde kan dukke opp i begge filtrene)
antall_serverclicks <- nrow(serverclicks)
totale_klikk <- nrow(x_klikk)
totale_unike_klikkere <- n_distinct(x_klikk$KundeNr)
# Beregn serverclick-rate
serverclick_pct_klikk <- (antall_serverclicks / totale_klikk) * 100
serverclick_pct_unike <- (antall_serverclicks / totale_unike_klikkere) * 100
### ðŸ“Œ 5. Skriv ut resultater
cat("\nðŸ” **Serverclick-analyse** ðŸ”\n")
cat("1ï¸âƒ£ Totalt antall klikk:", totale_klikk, "\n")
cat("2ï¸âƒ£ Totalt antall unike klikkere:", totale_unike_klikkere, "\n")
cat("3ï¸âƒ£ Totalt antall serverclicks (mistanke):", antall_serverclicks, "\n")
cat("4ï¸âƒ£ Serverclicks som andel av alle klikk:", round(serverclick_pct_klikk, 2), "%\n")
cat("5ï¸âƒ£ Serverclicks som andel av unike klikkere:", round(serverclick_pct_unike, 2), "%\n")
### ðŸ“Œ 3. Finn serverclicks basert pÃ¥ klikk KORT tid etter Ã¥pning (f.eks. 10 sek)
serverclick_etter_apning <- x_klikk %>%
filter(!is.na(Ã…pnet)) %>%
mutate(tidsdiff = as.numeric(difftime(Dato_klikket, Ã…pnet, units = "secs"))) %>%
filter(tidsdiff <= 30) %>%  # Juster terskel (kan teste 10, 20, 30 sekunder)
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle)  # Klikk pÃ¥ alle artikler
### ðŸ“Œ 4. Kombiner og tell antall serverclicks
serverclicks <- bind_rows(serverclick_foer_apning, serverclick_etter_apning) %>%
distinct(KundeNr)  # Fjern duplikater (samme kunde kan dukke opp i begge filtrene)
antall_serverclicks <- nrow(serverclicks)
totale_klikk <- nrow(x_klikk)
totale_unike_klikkere <- n_distinct(x_klikk$KundeNr)
# Beregn serverclick-rate
serverclick_pct_klikk <- (antall_serverclicks / totale_klikk) * 100
serverclick_pct_unike <- (antall_serverclicks / totale_unike_klikkere) * 100
### ðŸ“Œ 5. Skriv ut resultater
cat("\nðŸ” **Serverclick-analyse** ðŸ”\n")
cat("1ï¸âƒ£ Totalt antall klikk:", totale_klikk, "\n")
cat("2ï¸âƒ£ Totalt antall unike klikkere:", totale_unike_klikkere, "\n")
cat("3ï¸âƒ£ Totalt antall serverclicks (mistanke):", antall_serverclicks, "\n")
cat("4ï¸âƒ£ Serverclicks som andel av alle klikk:", round(serverclick_pct_klikk, 2), "%\n")
cat("5ï¸âƒ£ Serverclicks som andel av unike klikkere:", round(serverclick_pct_unike, 2), "%\n")
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk konkmail utsid 124115.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
# Hent totalt antall artikler i brevet (fikset med `as.character()`)
total_artikler <- x %>%
filter(!is.na(ArtikkelId)) %>%
summarise(n_distinct(ArtikkelId)) %>%
pull()
cat("Totalt antall unike artikler i brevet:", total_artikler, "\n")
# Filtrer kun rader med registrerte klikk
x_klikk <- x %>% filter(!is.na(Dato_klikket))
### ðŸ“Œ 2. Finn serverclicks basert pÃ¥ klikk FÃ˜R Ã¥pning
serverclick_foer_apning <- x_klikk %>%
filter(Dato_klikket < Ã…pnet) %>%
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle | antall_klikkede_artikler >= 2)  # Klikk pÃ¥ alle eller minst 2 artikler
### ðŸ“Œ 3. Finn serverclicks basert pÃ¥ klikk KORT tid etter Ã¥pning (f.eks. 10 sek)
serverclick_etter_apning <- x_klikk %>%
filter(!is.na(Ã…pnet)) %>%
mutate(tidsdiff = as.numeric(difftime(Dato_klikket, Ã…pnet, units = "secs"))) %>%
filter(tidsdiff <= 0) %>%  # Juster terskel (kan teste 10, 20, 30 sekunder)
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle)  # Klikk pÃ¥ alle artikler
### ðŸ“Œ 4. Kombiner og tell antall serverclicks
serverclicks <- bind_rows(serverclick_foer_apning, serverclick_etter_apning) %>%
distinct(KundeNr)  # Fjern duplikater (samme kunde kan dukke opp i begge filtrene)
antall_serverclicks <- nrow(serverclicks)
totale_klikk <- nrow(x_klikk)
totale_unike_klikkere <- n_distinct(x_klikk$KundeNr)
# Beregn serverclick-rate
serverclick_pct_klikk <- (antall_serverclicks / totale_klikk) * 100
serverclick_pct_unike <- (antall_serverclicks / totale_unike_klikkere) * 100
### ðŸ“Œ 5. Skriv ut resultater
cat("\nðŸ” **Serverclick-analyse** ðŸ”\n")
cat("1ï¸âƒ£ Totalt antall klikk:", totale_klikk, "\n")
cat("2ï¸âƒ£ Totalt antall unike klikkere:", totale_unike_klikkere, "\n")
cat("3ï¸âƒ£ Totalt antall serverclicks (mistanke):", antall_serverclicks, "\n")
cat("4ï¸âƒ£ Serverclicks som andel av alle klikk:", round(serverclick_pct_klikk, 2), "%\n")
cat("5ï¸âƒ£ Serverclicks som andel av unike klikkere:", round(serverclick_pct_unike, 2), "%\n")
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/2F3F2F70-A162-4346-B44B-A466A6878CE8.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
# Hent totalt antall artikler i brevet (fikset med `as.character()`)
total_artikler <- x %>%
filter(!is.na(ArtikkelId)) %>%
summarise(n_distinct(ArtikkelId)) %>%
pull()
cat("Totalt antall unike artikler i brevet:", total_artikler, "\n")
# Filtrer kun rader med registrerte klikk
x_klikk <- x %>% filter(!is.na(Dato_klikket))
### ðŸ“Œ 2. Finn serverclicks basert pÃ¥ klikk FÃ˜R Ã¥pning
serverclick_foer_apning <- x_klikk %>%
filter(Dato_klikket < Ã…pnet) %>%
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle | antall_klikkede_artikler >= 2)  # Klikk pÃ¥ alle eller minst 2 artikler
### ðŸ“Œ 3. Finn serverclicks basert pÃ¥ klikk KORT tid etter Ã¥pning (f.eks. 10 sek)
serverclick_etter_apning <- x_klikk %>%
filter(!is.na(Ã…pnet)) %>%
mutate(tidsdiff = as.numeric(difftime(Dato_klikket, Ã…pnet, units = "secs"))) %>%
filter(tidsdiff <= 0) %>%  # Juster terskel (kan teste 10, 20, 30 sekunder)
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle)  # Klikk pÃ¥ alle artikler
### ðŸ“Œ 4. Kombiner og tell antall serverclicks
serverclicks <- bind_rows(serverclick_foer_apning, serverclick_etter_apning) %>%
distinct(KundeNr)  # Fjern duplikater (samme kunde kan dukke opp i begge filtrene)
antall_serverclicks <- nrow(serverclicks)
totale_klikk <- nrow(x_klikk)
totale_unike_klikkere <- n_distinct(x_klikk$KundeNr)
# Beregn serverclick-rate
serverclick_pct_klikk <- (antall_serverclicks / totale_klikk) * 100
serverclick_pct_unike <- (antall_serverclicks / totale_unike_klikkere) * 100
### ðŸ“Œ 5. Skriv ut resultater
cat("\nðŸ” **Serverclick-analyse** ðŸ”\n")
cat("1ï¸âƒ£ Totalt antall klikk:", totale_klikk, "\n")
cat("2ï¸âƒ£ Totalt antall unike klikkere:", totale_unike_klikkere, "\n")
cat("3ï¸âƒ£ Totalt antall serverclicks (mistanke):", antall_serverclicks, "\n")
cat("4ï¸âƒ£ Serverclicks som andel av alle klikk:", round(serverclick_pct_klikk, 2), "%\n")
cat("5ï¸âƒ£ Serverclicks som andel av unike klikkere:", round(serverclick_pct_unike, 2), "%\n")
y <- fread("~/Desktop/360 programmer/JN25-008/OD uttrekk konkmail utsid 124115.csv")
y <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk konkmail utsid 124115.csv")
y <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk konkmail utsid 124115.csv", fileEncoding = "UTF-16LE", sep = "\t")
head(y)
head(y, 20)
# Antall klikk (ikke-NA verdier i Dato_klikket)
antall_klikk <- sum(!is.na(y$Dato_klikket))
# Skriv ut resultatet
cat("Totalt antall klikk:", antall_klikk, "\n")
# Les inn CSV-fil og konverter til riktige formater
x <- read.delim("~/Desktop/360 programmer/JN25-008/OD uttrekk twe utsid 124098.csv",
fileEncoding = "UTF-16LE", sep = "\t") %>%
mutate(
Ã…pnet = as.POSIXct(Ã…pnet, format = "%d.%m.%Y %H:%M:%S"),
Sendt = as.POSIXct(Sendt, format = "%d.%m.%Y %H:%M:%S"),
Dato_klikket = as.POSIXct(Dato_klikket, format = "%d.%m.%Y %H:%M:%S"),
ArtikkelId = as.character(ArtikkelId)  # ðŸ”¹ Viktig konvertering!
)
# Hent totalt antall artikler i brevet (fikset med `as.character()`)
total_artikler <- x %>%
filter(!is.na(ArtikkelId)) %>%
summarise(n_distinct(ArtikkelId)) %>%
pull()
cat("Totalt antall unike artikler i brevet:", total_artikler, "\n")
# Filtrer kun rader med registrerte klikk
x_klikk <- x %>% filter(!is.na(Dato_klikket))
### ðŸ“Œ 2. Finn serverclicks basert pÃ¥ klikk FÃ˜R Ã¥pning
serverclick_foer_apning <- x_klikk %>%
filter(Dato_klikket < Ã…pnet) %>%
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle | antall_klikkede_artikler >= 2)  # Klikk pÃ¥ alle eller minst 2 artikler
### ðŸ“Œ 3. Finn serverclicks basert pÃ¥ klikk KORT tid etter Ã¥pning (f.eks. 10 sek)
serverclick_etter_apning <- x_klikk %>%
filter(!is.na(Ã…pnet)) %>%
mutate(tidsdiff = as.numeric(difftime(Dato_klikket, Ã…pnet, units = "secs"))) %>%
filter(tidsdiff <= 0) %>%  # Juster terskel (kan teste 10, 20, 30 sekunder)
group_by(KundeNr) %>%
summarise(
antall_klikkede_artikler = n_distinct(ArtikkelId),
klikket_alle = antall_klikkede_artikler == total_artikler
) %>%
filter(klikket_alle)  # Klikk pÃ¥ alle artikler
### ðŸ“Œ 4. Kombiner og tell antall serverclicks
serverclicks <- bind_rows(serverclick_foer_apning, serverclick_etter_apning) %>%
distinct(KundeNr)  # Fjern duplikater (samme kunde kan dukke opp i begge filtrene)
antall_serverclicks <- nrow(serverclicks)
totale_klikk <- nrow(x_klikk)
totale_unike_klikkere <- n_distinct(x_klikk$KundeNr)
# Beregn serverclick-rate
serverclick_pct_klikk <- (antall_serverclicks / totale_klikk) * 100
serverclick_pct_unike <- (antall_serverclicks / totale_unike_klikkere) * 100
### ðŸ“Œ 5. Skriv ut resultater
cat("\nðŸ” **Serverclick-analyse** ðŸ”\n")
cat("1ï¸âƒ£ Totalt antall klikk:", totale_klikk, "\n")
cat("2ï¸âƒ£ Totalt antall unike klikkere:", totale_unike_klikkere, "\n")
cat("3ï¸âƒ£ Totalt antall serverclicks (mistanke):", antall_serverclicks, "\n")
cat("4ï¸âƒ£ Serverclicks som andel av alle klikk:", round(serverclick_pct_klikk, 2), "%\n")
cat("5ï¸âƒ£ Serverclicks som andel av unike klikkere:", round(serverclick_pct_unike, 2), "%\n")
x <- fread("~/Desktop/wasteson/TrackSights/data/Bilbasen biler 1903 2024.xlsx")
x <- readxl::("~/Desktop/wasteson/TrackSights/data/Bilbasen biler 1903 2024.xlsx")
x <- readxl::"~/Desktop/wasteson/TrackSights/data/Bilbasen biler 1903 2024.xlsx"
x <- read_excel("~/Desktop/wasteson/TrackSights/data/Bilbasen biler 1903 2024.xlsx")
library(readxl)
x <- read_excel("~/Desktop/wasteson/TrackSights/data/Bilbasen biler 1903 2024.xlsx")
dim(x)
head(x)
x <- read.delim("~/Desktop/360 programmer/JN25-067/Bounce_124227_mobil.txt")
x <- read.delim("~/Desktop/360 programmer/JN25-067/Bounce_124227_mobil.txt", fileEncoding = "latin1")
dim(x)
head(x, 3)
# Finn rader der e-postadressen matcher eksakt
x[x$E.post == "aubentse@online.no", ]
x <- read.delim("~/Desktop/360 programmer/JN25-073/8814922D-5F9A-4425-81F7-6090C48A9670.csv")
x <- read.delim("~/Desktop/360 programmer/JN25-073/8814922D-5F9A-4425-81F7-6090C48A9670.csv", fileEncoding = "latin1")
dim(x)
head(x, 3)
library(readr)
# Les hele fila som rÃ¥tekst
raw_data <- read_file_raw("~/Desktop/360 programmer/JN25-073/8814922D-5F9A-4425-81F7-6090C48A9670.csv")
# Konverter til riktig tekst (UTF-16 LE -> UTF-8)
text_data <- iconv(rawToChar(raw_data), from = "UTF-16LE", to = "UTF-8")
# Konverter rÃ¥data til tekst â€“ OBS: bruk tolkning av hele bytestreamen
text_data <- iconv(list(raw_data), from = "UTF-16LE", to = "UTF-8")
# Skriv til midlertidig fil
writeLines(text_data, "temp_utf8.csv")
# Les inn den konverterte fila
x <- read.csv("temp_utf8.csv", stringsAsFactors = FALSE)
dim(x)
head(x, 3)
# Les inn den konverterte fila
x <- read.csv("temp_utf8.csv", stringsAsFactors = FALSE, sep = "\t")
dim(x)
head(x, 3)
# Finn rader der e-postadressen matcher eksakt
x[x$E.post == "aubentse@online.no", ]
x <- read.delim("~/Desktop/360 programmer/JN25-058/Bounce_124347_21052025.txt")
x <- read.delim("~/Desktop/360 programmer/JN25-058/Bounce_124347_21052025.txt", fileEncoding = "latin1")
dim(x)
y <- read.delim("~/Desktop/360 programmer/JN25-058/Bounce_124348_21052025.txt", fileEncoding = "latin1")
z <- read.delim("~/Desktop/360 programmer/JN25-058/Bounce_124349_21052025.txt", fileEncoding = "latin1")
# Finn rader der e-postadressen matcher eksakt
x[x$E.post == "aubentse@online.no", ]
z <- read.delim("~/Desktop/360 programmer/JN25-058/Bounce_124349_21052025.txt", fileEncoding = "latin1")
# Finn rader der e-postadressen matcher eksakt
x[x$E.post == "aubentse@online.no", ]
table(x$ReturÃ¥rsak)
x <- read.delim("~/Desktop/360 programmer/JN25-058/Bounce_124347_21052025.txt", fileEncoding = "latin1")
dim(x)
# Finn rader der e-postadressen matcher eksakt
x[x$E.post == "aubentse@online.no", ]
rm(df, tbl, table_id)
gc()
main <- read.delim"~/Desktop/360 programmer/JN25-003/telenor_auto_modelid_3989701_syncid_2512430_2025_06_18_13_46_12_main.csv")
main <- read.delim("~/Desktop/360 programmer/JN25-003/telenor_auto_modelid_3989701_syncid_2512430_2025_06_18_13_46_12_main.csv")
sub <- read.delim("~/Desktop/360 programmer/JN25-003/telenor_auto_modelid_3942868_syncid_2512453_2025_06_18_14_39_59_sub.csv")
dim(main)
dim(sub)
head(main,1)
head(sub,1)
# 1. Tell hvor mange ganger hver KURT forekommer i sub
sub_counts <- sub %>%
count(KURT, name = "antall_i_sub")
library(dplyr)
# 1. Tell hvor mange ganger hver KURT forekommer i sub
sub_counts <- sub %>%
count(KURT, name = "antall_i_sub")
# 2. SlÃ¥ dette sammen med main â€“ og behold bare de som finnes i sub
main_med_telling <- main %>%
left_join(sub_counts, by = "KURT") %>%
filter(!is.na(antall_i_sub))
# 3. Hent ut unike forekomster av antall_i_sub og velg f.eks. 1, 2 og 3
unike_antall <- main_med_telling %>%
distinct(antall_i_sub) %>%
filter(antall_i_sub %in% c(1, 2, 3))  # du kan endre dette til Ã¸nsket variasjon
# 4. For hver av disse: hent Ã©n tilfeldig KURT som har dette antallet
tre_kurt_med_ulikt_antall <- main_med_telling %>%
semi_join(unike_antall, by = "antall_i_sub") %>%
group_by(antall_i_sub) %>%
slice_sample(n = 1) %>%
ungroup()
# Se antall forekomster i sub for de tre valgte KURT
tre_kurt_med_ulikt_antall %>%
dplyr::select(KURT, antall_i_sub)
# Lag en vektor med de tre KURT-verdiene
valgte_kurt <- tre_kurt_med_ulikt_antall$KURT
# Filtrer main: kun rader med de tre valgte KURT
main_uttrekk <- main %>%
filter(KURT %in% valgte_kurt)
# Filtrer sub: alle rader som matcher disse KURT-verdiene
sub_uttrekk <- sub %>%
filter(KURT %in% valgte_kurt)
dim(main_uttrekk)
dim(sub_uttrekk)
n_distinct(main$CUST_ID)
n_distinct(main$KURT)
head(main_uttrekk)
head(sub_uttrekk)
install.packages("flexdashboard", type = "source")
install.packages("flexdashboard", type = "source")
# Installer devtools hvis du ikke har det
install.packages("devtools")
# Installer flexdashboard direkte fra GitHub
devtools::install_github("rstudio/flexdashboard")
Sys.setenv(GITHUB_PAT = "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")
devtools::install_github("rstudio/flexdashboard")
library(bigrquery)
library(rmarkdown)
# Hent data fra BigQuery
project <- "imposing-yen-426717-u4"
sql <- "SELECT * FROM `imposing-yen-426717-u4.wasteson_insight_fuel_data.daily_fuel_share`"
df <- bq_project_query(project, sql) %>%
bq_table_download()
setwd("~/Desktop/wasteson/TrackSights/datating/looker/bigquery_2 auto drivstof analyse")
library(dplyr)
# Hent data fra BigQuery
project <- "imposing-yen-426717-u4"
sql <- "SELECT * FROM `imposing-yen-426717-u4.wasteson_insight_fuel_data.daily_fuel_share`"
df <- bq_project_query(project, sql) %>%
bq_table_download()
bigrquery::bq_auth(path = NULL)  # Nullstiller
# Hent data fra BigQuery
project <- "imposing-yen-426717-u4"
sql <- "SELECT * FROM `imposing-yen-426717-u4.wasteson_insight_fuel_data.daily_fuel_share`"
df <- bq_project_query(project, sql) %>%
bq_table_download()
# Lagre som CSV slik dashboardet kan bruke det
write.csv(df, "daily_fuel_market.csv", row.names = FALSE)
# Knit dashboardet
rmarkdown::render("fuel_dashboard.Rmd", output_file = "index.html")
source("fuel_dashboard_update.R")
system("cd '/Users/oystein/Desktop/wasteson/TrackSights/datating/looker/bigquery_2 auto drivstof analyse' && git add index.html && git commit -m 'Auto update dashboard' && git push origin main")
setwd("~/Desktop/wasteson/TrackSights/datating/looker/bigquery_3 auto merke og model analyse")
